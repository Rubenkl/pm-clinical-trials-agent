# Backend - FastAPI with OpenAI Agents SDK

## ‚ö†Ô∏è IMPORTANT: Before Starting Backend Work
1. **Review Project Plans**: Check `/product-management/roadmaps/` for:
   - `backend-development-tasks.md` - Comprehensive task list with priorities
   - `sprint-execution-plan.md` - Current sprint goals and what to work on
   - `master-implementation-plan-2025.md` - Overall timeline and dependencies

2. **Current Sprint Focus**: Always align work with the current sprint objectives

3. **Task Priority**: Follow the priority matrix:
   - Critical Path (Must Complete First)
   - High Priority (Core Functionality)
   - Medium Priority (Enhanced Features)
   - Lower Priority (Nice to Have)

## Overview
The backend leverages the **OpenAI Agents SDK** for multi-agent orchestration with FastAPI as a lightweight API wrapper. The SDK provides built-in agent communication, state management, and orchestration patterns - eliminating the need for complex database models or custom agent frameworks.

## üß™ Agent Testing & Evaluation Strategy

### Agent Architecture Philosophy
Our agents are **prompt-based LLM systems**, not trained models. This means:
- **Core Logic**: Carefully crafted prompts that define agent behavior
- **Intelligence**: Leveraged from base LLM (GPT-4) capabilities  
- **Specialization**: Domain-specific prompts and response parsing
- **Validation**: Ground truth datasets to measure performance

### Testing Approach
1. **Unit Tests**: Test agent structure, configuration, and non-LLM logic
2. **Integration Tests**: Test agent coordination and handoffs (mocked responses)
3. **Performance Tests**: Test agents against ground truth datasets (requires OpenAI API)
4. **Evaluation Metrics**: Precision, recall, F1-score, accuracy for each agent capability

### Ground Truth Test Datasets
Located in `/tests/test_data/clinical_test_datasets.py`:
- **Discrepancy Detection**: 6 test cases with known EDC vs source document differences
- **Critical Data Identification**: 3 test cases with safety-critical scenarios
- **Pattern Detection**: Site-specific and temporal pattern scenarios
- **Performance Metrics**: Automated calculation of precision/recall/F1/accuracy

### Agent Performance Validation
```python
# Example evaluation approach
test_dataset = get_test_dataset("DISCREPANCY_001")
result = await data_verifier.cross_system_verification(
    test_dataset["edc_data"], 
    test_dataset["source_data"]
)
metrics = calculate_performance_metrics(
    result.discrepancies, 
    test_dataset["expected_discrepancies"]
)
assert metrics["precision"] >= 0.85  # Performance threshold
```

## Architecture

### Tech Stack
- **AI Orchestration**: OpenAI Agents SDK (handles all agent coordination)
- **API Framework**: FastAPI (lightweight wrapper for HTTP endpoints)
- **State Management**: SDK Context objects (in-memory with optional persistence)
- **Storage**: Simple PostgreSQL (only if persistence needed)
- **Server**: Hypercorn (for Railway deployment)
- **Deployment**: Railway with Docker

### OpenAI Agents SDK Features (Built-in)
‚úÖ **Agent-to-Agent Communication**: Via "Handoffs" - agents delegate to specialized sub-agents
‚úÖ **State Management**: Via "Context" objects - dependency injection for shared state
‚úÖ **Multi-Agent Orchestration**: LLM-driven and code-driven patterns
‚úÖ **Portfolio Manager Pattern**: Central agent coordinating specialists
‚úÖ **Built-in Tracing**: Workflow visualization and debugging
‚úÖ **Parallel Execution**: Agents run tools/sub-agents concurrently

### Directory Structure

```
backend/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ agents/          # OpenAI Agents SDK implementation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ portfolio_manager.py    # Central orchestrator agent
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ query_analyzer.py       # Query analysis specialist
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_verifier.py        # Data verification specialist
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ context.py              # Shared context/state management
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ handoffs.py             # Agent handoff definitions
‚îÇ   ‚îú‚îÄ‚îÄ api/             # FastAPI routes (lightweight wrapper)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ endpoints/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agents.py           # Agent interaction endpoints
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ health.py           # Health check endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/                 # Pydantic request/response models
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dependencies.py         # API dependencies
‚îÇ   ‚îú‚îÄ‚îÄ core/            # Core configurations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.py               # Application configuration
‚îÇ   ‚îî‚îÄ‚îÄ services/        # Optional services (if needed)
‚îú‚îÄ‚îÄ tests/               # Backend tests
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ test_agents.py              # Agent orchestration tests
‚îÇ   ‚îú‚îÄ‚îÄ test_api.py                 # FastAPI endpoint tests
‚îÇ   ‚îî‚îÄ‚îÄ conftest.py
‚îú‚îÄ‚îÄ requirements.txt     # Python dependencies
‚îú‚îÄ‚îÄ Dockerfile          # Railway deployment
‚îú‚îÄ‚îÄ railway.toml        # Railway configuration
‚îî‚îÄ‚îÄ main.py            # Application entry point
```

## Key Components

### Multi-Agent System (OpenAI Agents SDK)
The system uses the Portfolio Manager pattern with specialized agents:

1. **Portfolio Manager**: Central orchestrator that coordinates all other agents
2. **Query Analyzer**: Analyzes and interprets user queries
3. **Data Verifier**: Validates and verifies data integrity
4. **Additional Specialists**: As needed for specific domains

### SDK-Based Orchestration Patterns
- **Handoffs**: Agents delegate specific tasks to specialized sub-agents
- **Context Sharing**: Shared state flows between agents via Context objects
- **Parallel Execution**: Multiple agents can work concurrently
- **Code-driven Flow**: Deterministic workflows using Python control structures

### FastAPI Wrapper
- **Minimal Endpoints**: Simple HTTP interface to the agent system
- **Pydantic Models**: Request/response validation
- **Health Checks**: System status monitoring
- **No Complex Database**: State managed by SDK Context objects

## Development Setup

### Installation
```bash
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### Environment Variables
```bash
# Required
OPENAI_API_KEY=your_openai_api_key

# Optional
PORT=8000
DEBUG=true
CORS_ORIGINS=http://localhost:3000
```

### Running Locally
```bash
uvicorn app.main:app --reload --port 8000
```

## API Documentation

### Agent Endpoints
- `POST /api/v1/agents/chat` - Chat with Portfolio Manager (orchestrates other agents)
- `GET /api/v1/agents/status` - Get agent system status
- `POST /api/v1/agents/reset` - Reset agent context/state

### Health Check
- `GET /health` - Application health status

## Agent Implementation Example

### Portfolio Manager Agent
```python
from openai_agents import Agent, Runner
from app.agents.context import WorkflowContext
from app.agents.handoffs import query_analyzer_handoff, data_verifier_handoff

portfolio_manager = Agent(
    name="Portfolio Manager",
    instructions="You coordinate specialized agents to fulfill user requests.",
    handoffs=[query_analyzer_handoff, data_verifier_handoff]
)

# Usage
context = WorkflowContext(user_request="Analyze this data")
result = Runner.run_sync(portfolio_manager, "Analyze user query", context=context)
```

### Context Management
```python
class WorkflowContext:
    def __init__(self):
        self.user_request = ""
        self.analysis_results = {}
        self.verification_status = ""
        self.workflow_state = "pending"
```

## Dependencies (requirements.txt)
```
# FastAPI and ASGI
fastapi==0.104.1
uvicorn[standard]==0.24.0
pydantic==2.5.0
pydantic-settings==2.1.0

# OpenAI Agents SDK
openai>=1.87.0
openai-agents>=0.1.0

# Simple PostgreSQL (only if persistent storage needed)
psycopg2-binary==2.9.9

# Testing
pytest==7.4.3
pytest-asyncio==0.21.1
pytest-cov==4.1.0

# Utilities
python-dotenv==1.0.0
```

## Testing
```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=app tests/

# Run agent tests specifically
pytest tests/test_agents.py -v
```

## Key Benefits of This Approach

### ‚úÖ What We Get for Free (SDK Built-in):
- Agent orchestration and communication
- State management via Context objects
- Built-in tracing and debugging
- Parallel agent execution
- Handoff patterns for delegation

### ‚úÖ What We Focus On:
- Business logic in agent instructions
- FastAPI endpoint design
- Request/response models
- Agent specialization and coordination

### ‚ùå What We DON'T Need:
- Complex database models/ORM
- Custom agent communication protocols
- Manual state management systems
- Custom orchestration frameworks

This approach leverages the OpenAI Agents SDK's powerful built-in features while keeping our implementation focused on the actual business requirements rather than infrastructure complexity.